{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import random\n",
    "import seaborn as sns\n",
    "from scipy import stats as stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "## kNN using dataset on heart disease obtained from https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "#### Data attributes:\n",
    "* age: age in years \n",
    "* sex: sex (1 = male; 0 = female) \n",
    "* cp: chest pain type \n",
    "    - Value 1: typical angina \n",
    "    - Value 2: atypical angina \n",
    "    - Value 3: non-anginal pain \n",
    "    - Value 4: asymptomatic \n",
    "* trestbps: resting blood pressure (in mm Hg on admission to the hospital) \n",
    "* chol: serum cholestoral in mg/dl \n",
    "* fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) \n",
    "* restecg: resting electrocardiographic results \n",
    "    - Value 0: normal \n",
    "    - Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) \n",
    "    - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria \n",
    "* thalach: maximum heart rate achieved \n",
    "* exang: exercise induced angina (1 = yes; 0 = no) \n",
    "* oldpeak = ST depression induced by exercise relative to rest \n",
    "* slope: the slope of the peak exercise ST segment \n",
    "    - Value 1: upsloping \n",
    "    - Value 2: flat \n",
    "    - Value 3: downsloping \n",
    "* ca: number of major vessels (0-3) colored by flourosopy \n",
    "* thal: 3 = normal; 6 = fixed defect; 7 = reversable defect \n",
    "* num: diagnosis of heart disease (angiographic disease status) \n",
    "    - Value 0: absence.\n",
    "    - Value 1,2,3,4: presence of heart disease"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe and modify num column to reflect presence of disease (1) or no presence of disase (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./cleveland.csv')\n",
    "df = df.rename({'num':'disease'}, axis=1)\n",
    "\n",
    "#convert disease column in to boolean values that 0 means no disease and >0 means has disease\n",
    "df['disease'] = df.disease.apply(lambda x: min(x, 1))\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the data for set of attributes\n",
    "df['age_s'] = (df.age-df.age.mean())/df.age.std()\n",
    "df['trestbps_s'] = (df.trestbps-df.trestbps.mean())/df.trestbps.std()\n",
    "df['chol_s'] = (df.chol-df.chol.mean())/df.chol.std()\n",
    "df['thalach_s'] = (df.thalach-df.thalach.mean())/df.thalach.std()\n",
    "df['oldpeak_s'] = (df.oldpeak-df.oldpeak.mean())/df.oldpeak.std()\n",
    "\n",
    "#data cleaning\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "# We'll also convert these types to floats since the '?' forced them to be strings\n",
    "df=df.apply(pd.to_numeric)\n",
    "\n",
    "# #general standardization\n",
    "# numeric_columns = df.select_dtypes(include=np.number).columns\n",
    "# df[numeric_columns] = (df[numeric_columns] - df[numeric_columns].mean()) / df[numeric_columns].std()\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimal attribute selection with GirdSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#modify the standardized dataset for implementation\n",
    "df1=df[['age_s','trestbps_s','chol_s','thalach_s','oldpeak_s','disease']] #,'sex','cp','fbs','restecg','slope','ca','thal'\n",
    "\n",
    "X1=df1.drop('disease',axis=1)\n",
    "#display(X1.head())\n",
    "y1=df1['disease']\n",
    "#display(y1.head())\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "forest_params = [{'max_depth': list(range(5, 11)), 'max_features': list(range(0,6))}]\n",
    "clf = GridSearchCV(rfc, forest_params, cv = 10, scoring='accuracy')\n",
    "clf.fit(X1_train, y1_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimal value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(k):\n",
    "  # Use knn on age. First create a nearest neighbors object.\n",
    "  nn = NearestNeighbors(n_neighbors=k, metric='euclidean', algorithm='auto')\n",
    "\n",
    "  # This builds an index data structure under the hood for query performance\n",
    "  X = df[['age_s', 'trestbps_s','chol_s','thalach_s','oldpeak_s','disease']].values\n",
    "  fit = nn.fit(X)\n",
    "\n",
    "  # Get random patients to test on\n",
    "  n = 50\n",
    "  patients = df.sample(n)\n",
    "  patientsX = patients[['age_s','trestbps_s','chol_s','thalach_s','oldpeak_s','disease']].values\n",
    "  patientsy = patients[['disease']].values\n",
    "  # display(patients)\n",
    "\n",
    "  # Find the k nearest neighbors to the patient.\n",
    "  distances, indices = fit.kneighbors(patientsX)\n",
    "  # print('indices of k-nearest neighbors for each patient:')\n",
    "  # display(indices)\n",
    "\n",
    "  y_pred = []\n",
    "  for i in range(n):\n",
    "      # print('nearest neighbors to patient: {}:'.format(patientsX[i]))\n",
    "      nbrs = df.iloc[indices[i]]\n",
    "      # Drop the patient of interest\n",
    "      nbrs = nbrs.drop(patients.index[i], errors='ignore')\n",
    "      # display(nbrs)\n",
    "\n",
    "      healthy = nbrs[nbrs.disease == 0].count().disease\n",
    "      sick = nbrs[nbrs.disease == 1].count().disease\n",
    "      predict = 0 if (healthy > sick) else 1\n",
    "      # print(f'healthy: {healthy}, sick: {sick}, predicted: {predict}, actual: {patientsy[i][0]}')\n",
    "      y_pred.append(predict)\n",
    "\n",
    "  # This is where we would compile how many patients are predicted\n",
    "  # correctly. Remember:\n",
    "  #    precision = tp/(tp+fp)  (\"sloppiness\")\n",
    "  #    recall    = tp/(tp+fn)  (\"What percentage did we find?\")\n",
    "  #    f-score - a balance between precision and recall\n",
    "  #    support - number of positive labels\n",
    "  return precision_recall_fscore_support(patientsy, y_pred, labels=[1])\n",
    "\n",
    "kvals = range(2, 40, 2)\n",
    "scores = [get_scores(k) for k in kvals]\n",
    "# print(scores)\n",
    "\n",
    "scores = [(p[0], r[0], f[0], s[0]) for (p,r,f,s) in scores]\n",
    "scores = list(zip(*scores))\n",
    "\n",
    "plt.plot(kvals, scores[2],marker=\"o\",label='f_score')\n",
    "plt.plot(kvals, scores[0],marker=\"o\",label='precision')\n",
    "plt.plot(kvals, scores[1],marker=\"o\",label='recall')\n",
    "plt.xlabel('k-values')\n",
    "plt.ylabel('scores')\n",
    "plt.legend()\n",
    "plt.title('plot for precision,recall and f_scores')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It could be seen that k=13 has the highest f-score which has better recall and precision values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monte carlo simulation & cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "def monte_carlo_cross_validation(df: pd.DataFrame, label: str, \n",
    "                                 model: NearestNeighbors, \n",
    "                                 iterations: int,\n",
    "                                 features: list = None, \n",
    "                                 min_test_split: float= 0.15, \n",
    "                                 max_test_split: float = 0.35) -> dict:\n",
    "  # https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b#9a83\n",
    "  # https://stats.stackexchange.com/a/60967\n",
    "  assert 0 < min_test_split < 1, \"min_test_split must be between 0 and 1!\"\n",
    "  assert 0 < max_test_split < 1, \"max_test_split must be between 0 and 1!\"\n",
    "\n",
    "  # Correct any issue with the list of features\n",
    "  if features is None:\n",
    "    features = [c for c in df.columns if c != label]\n",
    "  elif not isinstance(features, list):\n",
    "    features = [features]\n",
    "\n",
    "  # Can't use rows with NaN\n",
    "  df = df.dropna()\n",
    "\n",
    "  all_features = df[features].values\n",
    "  all_labels = df[label].values\n",
    "\n",
    "  results = {\n",
    "      \"precision\": 0,\n",
    "      \"recall\": 0,\n",
    "      \"f-score\": 0,\n",
    "      \"support\": 0\n",
    "  }\n",
    "  dfAllScores = pd.DataFrame(columns=results.keys())\n",
    "  # Perform the validation\n",
    "  for _ in range(iterations):\n",
    "    # Create the split\n",
    "    test_split = random.uniform(min_test_split, max_test_split)\n",
    "    features_train, features_test, labels_train, labels_test = \\\n",
    "      train_test_split(all_features, all_labels, test_size=test_split)\n",
    "    \n",
    "    # Fit the model\n",
    "    fit = model.fit(features_train)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    distances, indices = fit.kneighbors(features_test)\n",
    "\n",
    "    # Get the predictions\n",
    "    predictions = []\n",
    "    for i in range(len(features_test)):\n",
    "      neighbor_indices = indices[i]\n",
    "      neighbor_labels = labels_train[neighbor_indices]\n",
    "      unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "      # neighbor_counts = dict(zip(unique, counts))\n",
    "      # has_not = neighbor_counts[False] if False in neighbor_counts else 0\n",
    "      # has = neighbor_counts[True] if True in neighbor_counts else 0\n",
    "      # predictions.append(0 if (has_not > has) else 1)\n",
    "      prediction = max(zip(unique, counts), key=lambda t: t[1])[0]\n",
    "      predictions.append(prediction)\n",
    "\n",
    "    # Calculate the scores\n",
    "    # TODO: I think I could do this after all iterations using a 2D array\n",
    "    p, r, f, s = precision_recall_fscore_support(labels_test, predictions, labels=[1])\n",
    "    \n",
    "    # Update the results\n",
    "    dfAllScores.loc[len(dfAllScores)] = {\n",
    "      \"precision\": p[0],\n",
    "      \"recall\": r[0],\n",
    "      \"f-score\": f[0],\n",
    "      \"support\": s[0]\n",
    "    }\n",
    "  # Average the results\n",
    "  results[\"precision\"] = dfAllScores[\"precision\"].mean()\n",
    "  results[\"recall\"] = dfAllScores[\"recall\"].mean()\n",
    "  results[\"f-score\"] = dfAllScores[\"f-score\"].mean()\n",
    "  results[\"support\"] = dfAllScores[\"support\"].mean()\n",
    "  return results, dfAllScores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### give range for k, number of k-fold cross validation, get scores and plot optimal k-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfKResults = pd.DataFrame(columns=[\"k\", \"precision\", \"recall\", \"f-score\", \"support\"])\n",
    "dfKResults.set_index('k', inplace=True)\n",
    "dfKAllScores = pd.DataFrame(columns=[\"k\", \"precision\", \"recall\", \"f-score\", \"support\"])\n",
    "\n",
    "for k in range(2, 21,1):\n",
    "  nn = NearestNeighbors(n_neighbors=k, metric='euclidean', algorithm='auto')\n",
    "  results, dfAllScores = monte_carlo_cross_validation(df, \"disease\", nn, iterations=10,min_test_split=0.20, max_test_split=0.30)\n",
    "  dfAllScores['k'] = k\n",
    "  dfKResults.loc[k] = results\n",
    "  dfKAllScores = pd.concat([dfKAllScores, dfAllScores])\n",
    "\n",
    "dfKResults.reset_index(inplace=True)\n",
    "dfKAllScores.set_index('k', inplace=True)\n",
    "print(\"Averages\")\n",
    "display(dfKResults)\n",
    "\n",
    "ax1=sns.lineplot(x='k', y='recall', data=dfKResults, marker=\"o\", label=\"recall\");\n",
    "ax2=sns.lineplot(x='k', y='precision', data=dfKResults, marker='o', label=\"precision\");\n",
    "ax1.lines[0].set_linestyle(\"--\")\n",
    "ax2.lines[1].set_linestyle(\"--\")\n",
    "ax = sns.lineplot(x='k', y='f-score', data=dfKResults, marker='o', label=\"f-score\");\n",
    "#ax.set_ylim(0.4, 0.7);\n",
    "ax.set_xlabel('k_values')\n",
    "ax.set_ylabel('scores')\n",
    "ax.set_title('lineplot for precision,recall & f_scores')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It could be seen that k=13 has the highest f-score which has better recall and precision values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "## kNN using dataset on diabetes \n",
    "#### Dataset obtained from https://www.kaggle.com/datasets/houcembenmansour/predict-diabetes-based-on-diagnostic-measures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create dataframe \n",
    " * ### Transform gender and diabetes columns to numeric representation (0 or 1)\n",
    " * ### Transform chol_hdl_ratio, bmi, and waist_hip_ratio columns to float representations (instead of comma seperated numbers)\n",
    " * ### Drop patient_number column (essentially a second index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv('./diabetes.csv')\n",
    "\n",
    "diabetes_df['diabetes'] = diabetes_df.diabetes.apply(lambda x: 0 if x=='No diabetes' else 1)\n",
    "diabetes_df['gender'] = diabetes_df.gender.apply(lambda x: 0 if x=='female' else 1)\n",
    "diabetes_df['chol_hdl_ratio'] = diabetes_df.chol_hdl_ratio.apply(lambda x: float(str(x).replace(',', '.')))\n",
    "diabetes_df['bmi'] = diabetes_df.bmi.apply(lambda x: float(str(x).replace(',', '.')))\n",
    "diabetes_df['waist_hip_ratio'] = diabetes_df.waist_hip_ratio.apply(lambda x: float(str(x).replace(',', '.')))\n",
    "diabetes_df.drop(columns='patient_number', inplace=True)\n",
    "\n",
    "diabetes_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Make standardized versions of each column in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df['cholesterol_s'] = (diabetes_df.cholesterol-diabetes_df.cholesterol.mean())/diabetes_df.cholesterol.std()\n",
    "diabetes_df['glucose_s'] = (diabetes_df.glucose-diabetes_df.glucose.mean())/diabetes_df.glucose.std()\n",
    "diabetes_df['hdl_chol_s'] = (diabetes_df.hdl_chol-diabetes_df.hdl_chol.mean())/diabetes_df.hdl_chol.std()\n",
    "diabetes_df['chol_hdl_ratio_s'] = (diabetes_df.chol_hdl_ratio-diabetes_df.chol_hdl_ratio.mean())/diabetes_df.chol_hdl_ratio.std()\n",
    "diabetes_df['age_s'] = (diabetes_df.age-diabetes_df.age.mean())/diabetes_df.age.std()\n",
    "diabetes_df['gender_s'] = (diabetes_df.gender-diabetes_df.gender.mean())/diabetes_df.gender.std()\n",
    "diabetes_df['height_s'] = (diabetes_df.height-diabetes_df.height.mean())/diabetes_df.height.std()\n",
    "diabetes_df['weight_s'] = (diabetes_df.weight-diabetes_df.weight.mean())/diabetes_df.weight.std()\n",
    "diabetes_df['bmi_s'] = (diabetes_df.bmi-diabetes_df.bmi.mean())/diabetes_df.bmi.std()\n",
    "diabetes_df['systolic_bp_s'] = (diabetes_df.systolic_bp-diabetes_df.systolic_bp.mean())/diabetes_df.systolic_bp.std()\n",
    "diabetes_df['diastolic_bp_s'] = (diabetes_df.diastolic_bp-diabetes_df.diastolic_bp.mean())/diabetes_df.diastolic_bp.std()\n",
    "diabetes_df['waist_s'] = (diabetes_df.waist-diabetes_df.waist.mean())/diabetes_df.waist.std()\n",
    "diabetes_df['hip_s'] = (diabetes_df.hip-diabetes_df.hip.mean())/diabetes_df.hip.std()\n",
    "diabetes_df['waist_hip_ratio_s'] = (diabetes_df.waist_hip_ratio-diabetes_df.waist_hip_ratio.mean())/diabetes_df.waist_hip_ratio.std()\n",
    "\n",
    "diabetes_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create function get_scores() \n",
    " * ### takes a k value as input\n",
    " * ### builds a kNN model\n",
    " * ### returns the recall, precision, and f-score results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(k):\n",
    "    nn = NearestNeighbors(n_neighbors=k, metric='euclidean', algorithm='auto')\n",
    "\n",
    "    X = diabetes_df[['cholesterol_s', 'glucose_s', 'chol_hdl_ratio_s', 'bmi_s', 'systolic_bp_s', 'diastolic_bp_s', 'waist_hip_ratio_s']].values\n",
    "    y = diabetes_df[['diabetes']].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    # X_train is the training data set.\n",
    "    # y_train is the set of labels to all the data in x_train.\n",
    "    # X_test is the test data set.\n",
    "    # y_test is the set of labels to all the data in x_test.\n",
    "    \n",
    "    # print(X_train)\n",
    "\n",
    "    fit = nn.fit(X_train)\n",
    "\n",
    "    distances, indices = fit.kneighbors(X_test)\n",
    "\n",
    "    predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        # print('patient: ', X_test[i])\n",
    "        # print('paintent_d: ', y_test[i])\n",
    "        # print('indices: ', indices[i])\n",
    "        # nbrs_g = [X_train[index] for index in indices[i]]\n",
    "        # print('nbrs_g: ', nbrs_g)\n",
    "        nbrs_diabetes = [y_train[index] for index in indices[i]]\n",
    "        nbrs_diabetes = [x[0] for x in nbrs_diabetes]\n",
    "        # print('nbrs: ', nbrs)\n",
    "\n",
    "        diabetes = nbrs_diabetes.count(1)\n",
    "        # print('yes: ', diabetes)\n",
    "        no_diabetes = nbrs_diabetes.count(0)\n",
    "        # print('no: ', no_diabetes)\n",
    "\n",
    "        prediction = 0 if (no_diabetes > diabetes) else 1\n",
    "        predictions.append(prediction)\n",
    "    # return\n",
    "    return precision_recall_fscore_support(y_test, predictions, labels=[1])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Find the optimum k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = range(5, 30)\n",
    "scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    k_scores = []\n",
    "    for i in range(10):\n",
    "        k_scores.append(get_scores(k)[2][0])\n",
    "    scores.append(np.array(k_scores).mean())\n",
    "\n",
    "plt.figure()\n",
    "plt.title('k value vs f-score')\n",
    "plt.ylabel('f-score')\n",
    "plt.xlabel('k value')\n",
    "plt.plot(k_values, scores)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Build 10 kNN models with a k value of 8 and report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(10):\n",
    "    scores = get_scores(8)\n",
    "    results.append(scores)\n",
    "\n",
    "f_scores = [result[2][0] for result in results]\n",
    "mean_f = np.array(f_scores).mean()\n",
    "\n",
    "print('Mean f-score of all models: ', mean_f, '\\n')\n",
    "\n",
    "print('Individual Model Scores: ')\n",
    "for i in range(10):\n",
    "    print('\\tModel', i+1, ': precision =', results[i][0][0], 'recall =', results[i][1][0], 'f-score =', results[i][2][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
